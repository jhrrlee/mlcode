{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1086a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bc4dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93ed611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x  y   z\n",
       "7   7  1  19\n",
       "4   4  4  22\n",
       "15  7  1  19\n",
       "17  2  3  15\n",
       "8   1  2  10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = pd.read_csv(\"basic_sample.csv\") #z=x*2+y*3+2\n",
    "bs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3a7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6, 21],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 2,  4],\n",
       "       [ 3,  5],\n",
       "       [ 4,  6],\n",
       "       [ 5,  7],\n",
       "       [ 6,  2],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 2,  3],\n",
       "       [ 3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = bs.drop('z', axis='columns')\n",
    "#inputs_scaled = scaler.fit_transform(inputs)\n",
    "inputs = inputs.values.reshape(bs.shape[0],2)\n",
    "#inputs = np.reshape(bs.shape[0],2)\n",
    "#scaler = preprocessing.StandardScaler().fit(inputs)\n",
    "#inputs = scaler.transform(inputs)\n",
    "inputs\n",
    "#scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72150adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6179cc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [12],\n",
       "       [12],\n",
       "       [17],\n",
       "       [22],\n",
       "       [27],\n",
       "       [77],\n",
       "       [19],\n",
       "       [10],\n",
       "       [13],\n",
       "       [18],\n",
       "       [23],\n",
       "       [28],\n",
       "       [33],\n",
       "       [20],\n",
       "       [19],\n",
       "       [10],\n",
       "       [15],\n",
       "       [20]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = bs['z'].values.reshape(bs.shape[0],1)\n",
    "# = bs['z'].values\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373923ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c14c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.Sequential()\n",
    "#model.add(keras.Input(shape=(2,), name=\"input_layer\"))\n",
    "#model.add(layers.Dense(2, activation=\"relu\", name=\"hidden_layer\"))\n",
    "#model.add(layers.Dense(2, name=\"hidden_layer\"))\n",
    "#model.add(layers.Dense(1, name=\"output_layer\"))\n",
    "\n",
    "#model.add(keras.Input(shape=(2,)))\n",
    "#model.add(layers.Dense(2, activation=\"relu\"))\n",
    "#model.add(layers.Dense(1))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33bcc624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1.1,2.1], [2.1,3.1]]\n",
    "y = [2.2,3.2]\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b2dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones((3, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843e3396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895a0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model on a test input\n",
    "#x = tf.ones((3, 2))\n",
    "#y = model(x)\n",
    "#print(\"Number of weights after calling the model:\", len(model.weights))  # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22c8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='SGD',\n",
    "#              metrics=['accuracy'])\n",
    "#model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "#model.fit(inputs, z, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07093a6e",
   "metadata": {},
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value.\n",
    "            # The loss function is configured in `compile()`.\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                sample_weight=sample_weight,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "        \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        print(f'loss:{loss}, weights:{sample_weight}')\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics.\n",
    "        # Metrics are configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5def919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "#layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "#layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "#layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "#x = tf.ones((3, 3))\n",
    "#y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f3f3863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8b7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(inputs, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6004d",
   "metadata": {},
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_fn = loss_fn\n",
    "    def train(self, train_dataset, train_metric):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch_train, training=True)\n",
    "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
    "                    # tf.print(loss_value)\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                # Update training metric.\n",
    "                train_metric.update_state(y_batch_train, logits)\n",
    "                # Log every 5 batches.\n",
    "                if step % 5 == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(loss_value))\n",
    "                    )\n",
    "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
    "                    print(train_metric.result().numpy())\n",
    "                # Display metrics at the end of each epoch.\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9de8ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f4e94bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6, 21],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 2,  4],\n",
       "       [ 3,  5],\n",
       "       [ 4,  6],\n",
       "       [ 5,  7],\n",
       "       [ 6,  2],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 2,  3],\n",
       "       [ 3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7503b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#temp = arr('i', [1,2,3])\n",
    "temp = np.array([[1, 2]], dtype='int64')\n",
    "#np.array([1, 2, 3, 4], dtype='float32')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ef3565e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#temp = inputs[:5]\n",
    "#np.shape(temp)\n",
    "#temp.shape\n",
    "#np.reshape(inputs, (4, 2))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c531e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "#temp = temp.reshape(temp.shape[0],2)\n",
    "temp\n",
    "print(f'{temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37b3f506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-2.2969618]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(temp,training=True)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8e1e1",
   "metadata": {},
   "source": [
    "# Construct and compile an instance of CustomModel\n",
    "\n",
    "#outputs = keras.layers.Dense(2)(inputs)\n",
    "#model = CustomModel(inputs, outputs)\n",
    "#model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Construct and compile an instance of CustomModel\n",
    "input_layer = keras.Input(shape=(2,))\n",
    "hidden_layer = keras.layers.Dense(2)(input_layer)\n",
    "output_layer = keras.layers.Dense(1)(hidden_layer)\n",
    "#model = CustomModel(input_layer, output_layer)\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "#model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Just use `fit` as usual\n",
    "#x = np.random.random((1000, 32))\n",
    "#y = np.random.random((1000, 1))\n",
    "#model.fit(inputs, z, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b020d7",
   "metadata": {},
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "class custom_train:\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, optimizer_fn, loss_fn, metric_fn):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer_fn\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics = metric_fn\n",
    "\n",
    "    #tf.function\n",
    "    def test_step(self, x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        val_acc_metric.update_state(y, val_logits)\n",
    "\n",
    "    #tf.function\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'x:{x}, y:{y} {type(x)}')\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.metrics.update_state(y, logits)\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, inputs, outputs, epochs, batch_size, batch_log, loss_threshold):\n",
    "        total_samples=inputs.shape[0]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            start_time = time.time()\n",
    "          \n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step in range(batch_size):\n",
    "                x = np.array([], dtype='int64')\n",
    "                y = np.array([], dtype='int64')\n",
    "                random_index = random.randint(0, total_samples -1)\n",
    "                x  = inputs[random_index]\n",
    "                y  = outputs[random_index]\n",
    "                #print(f'x:{x}, y:{y} {type(x)}')\n",
    "\n",
    "                #loss_value = self.train_step(x,y)\n",
    "                loss_value = self.train_step(inputs, outputs)\n",
    "                # Log every in batch_log.\n",
    "                if step % batch_log == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(loss_value))\n",
    "                    )\n",
    "                    print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "            # Display metrics at the end of each epoch.\n",
    "            train_acc = self.metrics.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "            if loss_value <= loss_threshold:\n",
    "                break\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.metrics.reset_states()\n",
    "            \n",
    "            cost_list.append(cost)\n",
    "            epoch_list.append(i)\n",
    "            \n",
    "    def validation(self, train_dataset, train_metric):\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca6b06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and compile an instance of CustomModel\n",
    "\n",
    "#outputs = keras.layers.Dense(2)(inputs)\n",
    "#model = CustomModel(inputs, outputs)\n",
    "#model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    \n",
    "\n",
    "#model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Just use `fit` as usual\n",
    "#x = np.random.random((1000, 32))\n",
    "#y = np.random.random((1000, 1))\n",
    "#model.fit(inputs, z, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09342390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "class custom_train:\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, optimizer_fn, loss_fn, metric_fn):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer_fn\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics = metric_fn\n",
    "\n",
    "    #tf.function\n",
    "    def test_step(self, x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        val_acc_metric.update_state(y, val_logits)\n",
    "\n",
    "    #tf.function\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'x:{x}, y:{y} {type(x)}')\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.metrics.update_state(y, logits)\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, inputs, outputs, epochs, batch_size, batch_log, loss_threshold):\n",
    "        loss_list = []\n",
    "        epoch_list = []\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = self.train_step(inputs, outputs)\n",
    "            \n",
    "            # Display metrics at the end of each epoch.\n",
    "            train_acc = self.metrics.result()\n",
    "            \n",
    "            if epoch%50==0:\n",
    "                loss_list.append(loss_value)\n",
    "                epoch_list.append(epoch)\n",
    "                print(\n",
    "                    \"Training acc over epoch: %.4f Training loss (for one batch) at step %d: %.4f Time taken: %.2fs \" \n",
    "                    % (float(train_acc), epoch, float(loss_value), (time.time() - start_time))\n",
    "                )\n",
    "            if loss_value <= loss_threshold:\n",
    "                break\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.metrics.reset_states()\n",
    "            \n",
    "        return loss_list, epoch_list\n",
    "    \n",
    "    def validation(self, train_dataset, train_metric):\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a49a20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 19.0219 Training loss (for one batch) at step 0: 574.2057 Time taken: 0.02s \n",
      "Training acc over epoch: 18.0731 Training loss (for one batch) at step 50: 525.1398 Time taken: 0.63s \n",
      "Training acc over epoch: 17.0002 Training loss (for one batch) at step 100: 472.6606 Time taken: 1.31s \n",
      "Training acc over epoch: 15.8090 Training loss (for one batch) at step 150: 417.6745 Time taken: 1.91s \n",
      "Training acc over epoch: 14.5136 Training loss (for one batch) at step 200: 361.7417 Time taken: 2.53s \n",
      "Training acc over epoch: 13.1332 Training loss (for one batch) at step 250: 306.6383 Time taken: 3.12s \n",
      "Training acc over epoch: 11.6919 Training loss (for one batch) at step 300: 254.1489 Time taken: 3.74s \n",
      "Training acc over epoch: 10.2188 Training loss (for one batch) at step 350: 205.8872 Time taken: 4.38s \n",
      "Training acc over epoch: 8.7464 Training loss (for one batch) at step 400: 163.1383 Time taken: 5.01s \n",
      "Training acc over epoch: 7.4420 Training loss (for one batch) at step 450: 126.7348 Time taken: 5.67s \n",
      "Training acc over epoch: 6.3942 Training loss (for one batch) at step 500: 96.9870 Time taken: 6.30s \n",
      "Training acc over epoch: 5.5212 Training loss (for one batch) at step 550: 73.6841 Time taken: 6.85s \n",
      "Training acc over epoch: 4.7601 Training loss (for one batch) at step 600: 56.1719 Time taken: 7.41s \n",
      "Training acc over epoch: 4.0846 Training loss (for one batch) at step 650: 43.4961 Time taken: 7.97s \n",
      "Training acc over epoch: 3.5010 Training loss (for one batch) at step 700: 34.5785 Time taken: 8.55s \n",
      "Training acc over epoch: 3.0189 Training loss (for one batch) at step 750: 28.3827 Time taken: 9.12s \n",
      "Training acc over epoch: 2.7620 Training loss (for one batch) at step 800: 24.0328 Time taken: 9.78s \n",
      "Training acc over epoch: 2.6105 Training loss (for one batch) at step 850: 20.8664 Time taken: 10.34s \n",
      "Training acc over epoch: 2.4683 Training loss (for one batch) at step 900: 18.4291 Time taken: 10.91s \n",
      "Training acc over epoch: 2.3344 Training loss (for one batch) at step 950: 16.4356 Time taken: 11.50s \n",
      "Training acc over epoch: 2.2136 Training loss (for one batch) at step 1000: 14.7204 Time taken: 12.07s \n",
      "Training acc over epoch: 2.1019 Training loss (for one batch) at step 1050: 13.1930 Time taken: 12.65s \n",
      "Training acc over epoch: 1.9918 Training loss (for one batch) at step 1100: 11.8066 Time taken: 13.28s \n",
      "Training acc over epoch: 1.8837 Training loss (for one batch) at step 1150: 10.5375 Time taken: 13.89s \n",
      "Training acc over epoch: 1.7812 Training loss (for one batch) at step 1200: 9.3732 Time taken: 14.44s \n",
      "Training acc over epoch: 1.6823 Training loss (for one batch) at step 1250: 8.3063 Time taken: 15.01s \n",
      "Training acc over epoch: 1.5847 Training loss (for one batch) at step 1300: 7.3316 Time taken: 15.58s \n",
      "Training acc over epoch: 1.4889 Training loss (for one batch) at step 1350: 6.4445 Time taken: 16.19s \n",
      "Training acc over epoch: 1.3954 Training loss (for one batch) at step 1400: 5.6406 Time taken: 16.81s \n",
      "Training acc over epoch: 1.3046 Training loss (for one batch) at step 1450: 4.9153 Time taken: 17.40s \n",
      "Training acc over epoch: 1.2173 Training loss (for one batch) at step 1500: 4.2640 Time taken: 18.00s \n",
      "Training acc over epoch: 1.1333 Training loss (for one batch) at step 1550: 3.6820 Time taken: 18.57s \n",
      "Training acc over epoch: 1.0526 Training loss (for one batch) at step 1600: 3.1644 Time taken: 19.19s \n",
      "Training acc over epoch: 0.9753 Training loss (for one batch) at step 1650: 2.7066 Time taken: 19.84s \n",
      "Training acc over epoch: 0.9016 Training loss (for one batch) at step 1700: 2.3036 Time taken: 20.45s \n",
      "Training acc over epoch: 0.8315 Training loss (for one batch) at step 1750: 1.9508 Time taken: 21.10s \n",
      "Training acc over epoch: 0.7649 Training loss (for one batch) at step 1800: 1.6436 Time taken: 21.82s \n",
      "Training acc over epoch: 0.7019 Training loss (for one batch) at step 1850: 1.3777 Time taken: 22.40s \n",
      "Training acc over epoch: 0.6425 Training loss (for one batch) at step 1900: 1.1487 Time taken: 22.97s \n",
      "Training acc over epoch: 0.5866 Training loss (for one batch) at step 1950: 0.9527 Time taken: 23.59s \n",
      "Training acc over epoch: 0.5342 Training loss (for one batch) at step 2000: 0.7860 Time taken: 24.16s \n",
      "Training acc over epoch: 0.4861 Training loss (for one batch) at step 2050: 0.6450 Time taken: 24.73s \n",
      "Training acc over epoch: 0.4422 Training loss (for one batch) at step 2100: 0.5266 Time taken: 25.33s \n",
      "Training acc over epoch: 0.4014 Training loss (for one batch) at step 2150: 0.4276 Time taken: 25.94s \n",
      "Training acc over epoch: 0.3637 Training loss (for one batch) at step 2200: 0.3456 Time taken: 26.53s \n",
      "Training acc over epoch: 0.3288 Training loss (for one batch) at step 2250: 0.2779 Time taken: 27.14s \n",
      "Training acc over epoch: 0.2969 Training loss (for one batch) at step 2300: 0.2225 Time taken: 27.73s \n",
      "Training acc over epoch: 0.2690 Training loss (for one batch) at step 2350: 0.1774 Time taken: 28.32s \n",
      "Training acc over epoch: 0.2454 Training loss (for one batch) at step 2400: 0.1410 Time taken: 28.88s \n",
      "Training acc over epoch: 0.2238 Training loss (for one batch) at step 2450: 0.1118 Time taken: 29.49s \n",
      "Training acc over epoch: 0.2042 Training loss (for one batch) at step 2500: 0.0885 Time taken: 30.14s \n",
      "Training acc over epoch: 0.1864 Training loss (for one batch) at step 2550: 0.0701 Time taken: 30.71s \n",
      "Training acc over epoch: 0.1703 Training loss (for one batch) at step 2600: 0.0555 Time taken: 31.28s \n",
      "Training acc over epoch: 0.1557 Training loss (for one batch) at step 2650: 0.0442 Time taken: 31.88s \n",
      "Training acc over epoch: 0.1433 Training loss (for one batch) at step 2700: 0.0353 Time taken: 32.51s \n",
      "Training acc over epoch: 0.1323 Training loss (for one batch) at step 2750: 0.0285 Time taken: 33.08s \n",
      "Training acc over epoch: 0.1223 Training loss (for one batch) at step 2800: 0.0232 Time taken: 33.85s \n",
      "Training acc over epoch: 0.1134 Training loss (for one batch) at step 2850: 0.0191 Time taken: 34.55s \n",
      "Training acc over epoch: 0.1053 Training loss (for one batch) at step 2900: 0.0160 Time taken: 35.24s \n",
      "Training acc over epoch: 0.0981 Training loss (for one batch) at step 2950: 0.0136 Time taken: 35.87s \n",
      "Training acc over epoch: 0.0917 Training loss (for one batch) at step 3000: 0.0117 Time taken: 36.52s \n",
      "Training acc over epoch: 0.0859 Training loss (for one batch) at step 3050: 0.0103 Time taken: 37.18s \n"
     ]
    }
   ],
   "source": [
    "# Construct and compile an instance of CustomModel\n",
    "input_layer = keras.Input(shape=(2,))\n",
    "hidden_layer = keras.layers.Dense(2)(input_layer)\n",
    "output_layer = keras.layers.Dense(1)(hidden_layer)\n",
    "#model = CustomModel(input_layer, output_layer)\n",
    "#%%timeit -n1 -r1\n",
    "with tf.device('/GPU:0'):\n",
    "    #cpu_model.fit(x_train_scaled, y_train_categorical, epochs=1)\n",
    "    model = keras.Model(input_layer, output_layer)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_function = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "    metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "    my_train = custom_train(model, optimizer, loss_function, metric)\n",
    "    loss_list, epoch_list = my_train.train(inputs, z, 5000, 15, 5, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4e326cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b47869cfd0>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(epoch_list, loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d354460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([[3, 2]], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2e00347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.968765]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=x*2+y*3+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
