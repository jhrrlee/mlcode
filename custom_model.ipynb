{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e555c0",
   "metadata": {},
   "source": [
    "# Custom batch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1086a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93ed611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y   z\n",
       "6   6  21  77\n",
       "2   2   2  12\n",
       "15  7   1  19\n",
       "12  4   6  28\n",
       "5   5   5  27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = pd.read_csv(\"basic_sample.csv\") #z=x*2+y*3+2\n",
    "bs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3a7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6, 21],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 2,  4],\n",
       "       [ 3,  5],\n",
       "       [ 4,  6],\n",
       "       [ 5,  7],\n",
       "       [ 6,  2],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 2,  3],\n",
       "       [ 3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = bs.drop('z', axis='columns')\n",
    "inputs = inputs.values.reshape(bs.shape[0],2)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72150adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6179cc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [12],\n",
       "       [12],\n",
       "       [17],\n",
       "       [22],\n",
       "       [27],\n",
       "       [77],\n",
       "       [19],\n",
       "       [10],\n",
       "       [13],\n",
       "       [18],\n",
       "       [23],\n",
       "       [28],\n",
       "       [33],\n",
       "       [20],\n",
       "       [19],\n",
       "       [10],\n",
       "       [15],\n",
       "       [20]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = bs['z'].values.reshape(bs.shape[0],1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373923ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(inputs, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6004d",
   "metadata": {},
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_fn = loss_fn\n",
    "    def train(self, train_dataset, train_metric):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch_train, training=True)\n",
    "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
    "                    # tf.print(loss_value)\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                # Update training metric.\n",
    "                train_metric.update_state(y_batch_train, logits)\n",
    "                # Log every 5 batches.\n",
    "                if step % 5 == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(loss_value))\n",
    "                    )\n",
    "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
    "                    print(train_metric.result().numpy())\n",
    "                # Display metrics at the end of each epoch.\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9de8ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4e94bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6, 21],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 2,  4],\n",
       "       [ 3,  5],\n",
       "       [ 4,  6],\n",
       "       [ 5,  7],\n",
       "       [ 6,  2],\n",
       "       [ 7,  1],\n",
       "       [ 1,  2],\n",
       "       [ 2,  3],\n",
       "       [ 3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09342390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class custom_train:\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, optimizer_fn, loss_fn, metric_fn):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer_fn\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics = metric_fn\n",
    "\n",
    "    #tf.function\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'x:{x}, y:{y} {type(x)}')\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.metrics.update_state(y, logits)\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, inputs, outputs, epochs, batch_size, batch_log, loss_threshold):\n",
    "        loss_list = []\n",
    "        epoch_list = []\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = self.train_step(inputs, outputs)\n",
    "            \n",
    "            # Display metrics at the end of each epoch.\n",
    "            train_acc = self.metrics.result()\n",
    "            \n",
    "            if epoch%50==0:\n",
    "                loss_list.append(loss_value)\n",
    "                epoch_list.append(epoch)\n",
    "                print(\n",
    "                    \"Training acc over epoch: %.4f Training loss (for one batch) at step %d: %.4f Time taken: %.2fs \" \n",
    "                    % (float(train_acc), epoch, float(loss_value), (time.time() - start_time))\n",
    "                )\n",
    "            if loss_value <= loss_threshold:\n",
    "                break\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.metrics.reset_states()\n",
    "            \n",
    "        return loss_list, epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49a20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 26.8371 Training loss (for one batch) at step 0: 1109.6434 Time taken: 0.40s \n",
      "Training acc over epoch: 25.4958 Training loss (for one batch) at step 50: 1006.7225 Time taken: 0.96s \n",
      "Training acc over epoch: 24.2469 Training loss (for one batch) at step 100: 915.8417 Time taken: 1.51s \n",
      "Training acc over epoch: 22.9993 Training loss (for one batch) at step 150: 829.8531 Time taken: 2.03s \n",
      "Training acc over epoch: 21.7277 Training loss (for one batch) at step 200: 746.7721 Time taken: 2.56s \n",
      "Training acc over epoch: 20.4350 Training loss (for one batch) at step 250: 666.9426 Time taken: 3.07s \n",
      "Training acc over epoch: 19.1249 Training loss (for one batch) at step 300: 590.7771 Time taken: 3.57s \n",
      "Training acc over epoch: 17.8011 Training loss (for one batch) at step 350: 518.6499 Time taken: 4.11s \n",
      "Training acc over epoch: 16.4682 Training loss (for one batch) at step 400: 450.9133 Time taken: 4.68s \n",
      "Training acc over epoch: 15.1314 Training loss (for one batch) at step 450: 387.8983 Time taken: 5.21s \n",
      "Training acc over epoch: 13.7974 Training loss (for one batch) at step 500: 329.9050 Time taken: 5.72s \n",
      "Training acc over epoch: 12.4740 Training loss (for one batch) at step 550: 277.1849 Time taken: 6.22s \n",
      "Training acc over epoch: 11.1701 Training loss (for one batch) at step 600: 229.9203 Time taken: 6.73s \n",
      "Training acc over epoch: 9.8959 Training loss (for one batch) at step 650: 188.2021 Time taken: 7.24s \n",
      "Training acc over epoch: 8.6622 Training loss (for one batch) at step 700: 152.0112 Time taken: 7.75s \n",
      "Training acc over epoch: 7.4804 Training loss (for one batch) at step 750: 121.2054 Time taken: 8.29s \n",
      "Training acc over epoch: 6.3616 Training loss (for one batch) at step 800: 95.5158 Time taken: 8.79s \n",
      "Training acc over epoch: 5.3162 Training loss (for one batch) at step 850: 74.5540 Time taken: 9.32s \n",
      "Training acc over epoch: 4.5366 Training loss (for one batch) at step 900: 57.8340 Time taken: 9.85s \n",
      "Training acc over epoch: 3.8620 Training loss (for one batch) at step 950: 44.8007 Time taken: 10.39s \n",
      "Training acc over epoch: 3.3503 Training loss (for one batch) at step 1000: 34.8674 Time taken: 10.93s \n",
      "Training acc over epoch: 2.8952 Training loss (for one batch) at step 1050: 27.4532 Time taken: 11.50s \n",
      "Training acc over epoch: 2.5329 Training loss (for one batch) at step 1100: 22.0161 Time taken: 12.02s \n",
      "Training acc over epoch: 2.2468 Training loss (for one batch) at step 1150: 18.0782 Time taken: 12.55s \n",
      "Training acc over epoch: 2.0599 Training loss (for one batch) at step 1200: 15.2392 Time taken: 13.09s \n",
      "Training acc over epoch: 1.9373 Training loss (for one batch) at step 1250: 13.1801 Time taken: 13.62s \n",
      "Training acc over epoch: 1.8842 Training loss (for one batch) at step 1300: 11.6584 Time taken: 14.17s \n",
      "Training acc over epoch: 1.8507 Training loss (for one batch) at step 1350: 10.4976 Time taken: 14.77s \n",
      "Training acc over epoch: 1.8170 Training loss (for one batch) at step 1400: 9.5747 Time taken: 15.35s \n",
      "Training acc over epoch: 1.7775 Training loss (for one batch) at step 1450: 8.8070 Time taken: 15.93s \n",
      "Training acc over epoch: 1.7370 Training loss (for one batch) at step 1500: 8.1411 Time taken: 16.49s \n",
      "Training acc over epoch: 1.6962 Training loss (for one batch) at step 1550: 7.5438 Time taken: 17.02s \n",
      "Training acc over epoch: 1.6571 Training loss (for one batch) at step 1600: 6.9950 Time taken: 17.54s \n",
      "Training acc over epoch: 1.6178 Training loss (for one batch) at step 1650: 6.4829 Time taken: 18.08s \n",
      "Training acc over epoch: 1.5768 Training loss (for one batch) at step 1700: 6.0009 Time taken: 18.64s \n",
      "Training acc over epoch: 1.5341 Training loss (for one batch) at step 1750: 5.5453 Time taken: 19.18s \n",
      "Training acc over epoch: 1.4892 Training loss (for one batch) at step 1800: 5.1140 Time taken: 19.71s \n",
      "Training acc over epoch: 1.4426 Training loss (for one batch) at step 1850: 4.7061 Time taken: 20.26s \n",
      "Training acc over epoch: 1.3941 Training loss (for one batch) at step 1900: 4.3207 Time taken: 20.81s \n",
      "Training acc over epoch: 1.3443 Training loss (for one batch) at step 1950: 3.9574 Time taken: 21.34s \n",
      "Training acc over epoch: 1.2940 Training loss (for one batch) at step 2000: 3.6159 Time taken: 21.91s \n",
      "Training acc over epoch: 1.2435 Training loss (for one batch) at step 2050: 3.2955 Time taken: 22.45s \n",
      "Training acc over epoch: 1.1933 Training loss (for one batch) at step 2100: 2.9960 Time taken: 22.99s \n",
      "Training acc over epoch: 1.1435 Training loss (for one batch) at step 2150: 2.7166 Time taken: 23.55s \n",
      "Training acc over epoch: 1.0944 Training loss (for one batch) at step 2200: 2.4569 Time taken: 24.12s \n",
      "Training acc over epoch: 1.0461 Training loss (for one batch) at step 2250: 2.2162 Time taken: 24.67s \n",
      "Training acc over epoch: 0.9987 Training loss (for one batch) at step 2300: 1.9938 Time taken: 25.27s \n",
      "Training acc over epoch: 0.9524 Training loss (for one batch) at step 2350: 1.7889 Time taken: 25.79s \n",
      "Training acc over epoch: 0.9071 Training loss (for one batch) at step 2400: 1.6009 Time taken: 26.32s \n",
      "Training acc over epoch: 0.8630 Training loss (for one batch) at step 2450: 1.4288 Time taken: 26.85s \n",
      "Training acc over epoch: 0.8201 Training loss (for one batch) at step 2500: 1.2719 Time taken: 27.39s \n",
      "Training acc over epoch: 0.7786 Training loss (for one batch) at step 2550: 1.1293 Time taken: 27.91s \n",
      "Training acc over epoch: 0.7387 Training loss (for one batch) at step 2600: 1.0001 Time taken: 28.47s \n",
      "Training acc over epoch: 0.7002 Training loss (for one batch) at step 2650: 0.8836 Time taken: 29.01s \n",
      "Training acc over epoch: 0.6631 Training loss (for one batch) at step 2700: 0.7788 Time taken: 29.55s \n",
      "Training acc over epoch: 0.6273 Training loss (for one batch) at step 2750: 0.6849 Time taken: 30.09s \n",
      "Training acc over epoch: 0.5929 Training loss (for one batch) at step 2800: 0.6012 Time taken: 30.65s \n",
      "Training acc over epoch: 0.5599 Training loss (for one batch) at step 2850: 0.5267 Time taken: 31.27s \n",
      "Training acc over epoch: 0.5284 Training loss (for one batch) at step 2900: 0.4607 Time taken: 31.87s \n",
      "Training acc over epoch: 0.4982 Training loss (for one batch) at step 2950: 0.4024 Time taken: 32.46s \n",
      "Training acc over epoch: 0.4693 Training loss (for one batch) at step 3000: 0.3512 Time taken: 32.99s \n",
      "Training acc over epoch: 0.4419 Training loss (for one batch) at step 3050: 0.3064 Time taken: 33.52s \n",
      "Training acc over epoch: 0.4159 Training loss (for one batch) at step 3100: 0.2672 Time taken: 34.04s \n",
      "Training acc over epoch: 0.3911 Training loss (for one batch) at step 3150: 0.2331 Time taken: 34.58s \n",
      "Training acc over epoch: 0.3677 Training loss (for one batch) at step 3200: 0.2036 Time taken: 35.12s \n",
      "Training acc over epoch: 0.3456 Training loss (for one batch) at step 3250: 0.1781 Time taken: 35.68s \n",
      "Training acc over epoch: 0.3248 Training loss (for one batch) at step 3300: 0.1561 Time taken: 36.21s \n",
      "Training acc over epoch: 0.3052 Training loss (for one batch) at step 3350: 0.1372 Time taken: 36.74s \n",
      "Training acc over epoch: 0.2868 Training loss (for one batch) at step 3400: 0.1211 Time taken: 37.28s \n",
      "Training acc over epoch: 0.2695 Training loss (for one batch) at step 3450: 0.1072 Time taken: 37.81s \n",
      "Training acc over epoch: 0.2533 Training loss (for one batch) at step 3500: 0.0953 Time taken: 38.33s \n",
      "Training acc over epoch: 0.2381 Training loss (for one batch) at step 3550: 0.0852 Time taken: 38.90s \n",
      "Training acc over epoch: 0.2240 Training loss (for one batch) at step 3600: 0.0765 Time taken: 39.43s \n",
      "Training acc over epoch: 0.2109 Training loss (for one batch) at step 3650: 0.0691 Time taken: 39.96s \n",
      "Training acc over epoch: 0.1986 Training loss (for one batch) at step 3700: 0.0628 Time taken: 40.48s \n",
      "Training acc over epoch: 0.1872 Training loss (for one batch) at step 3750: 0.0573 Time taken: 41.01s \n",
      "Training acc over epoch: 0.1814 Training loss (for one batch) at step 3800: 0.0525 Time taken: 41.61s \n",
      "Training acc over epoch: 0.1762 Training loss (for one batch) at step 3850: 0.0484 Time taken: 42.17s \n",
      "Training acc over epoch: 0.1725 Training loss (for one batch) at step 3900: 0.0447 Time taken: 42.72s \n",
      "Training acc over epoch: 0.1687 Training loss (for one batch) at step 3950: 0.0415 Time taken: 43.31s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.1649 Training loss (for one batch) at step 4000: 0.0387 Time taken: 43.89s \n",
      "Training acc over epoch: 0.1611 Training loss (for one batch) at step 4050: 0.0361 Time taken: 44.56s \n",
      "Training acc over epoch: 0.1572 Training loss (for one batch) at step 4100: 0.0338 Time taken: 45.15s \n",
      "Training acc over epoch: 0.1533 Training loss (for one batch) at step 4150: 0.0316 Time taken: 45.75s \n",
      "Training acc over epoch: 0.1493 Training loss (for one batch) at step 4200: 0.0296 Time taken: 46.30s \n",
      "Training acc over epoch: 0.1454 Training loss (for one batch) at step 4250: 0.0278 Time taken: 46.86s \n",
      "Training acc over epoch: 0.1414 Training loss (for one batch) at step 4300: 0.0261 Time taken: 47.42s \n",
      "Training acc over epoch: 0.1374 Training loss (for one batch) at step 4350: 0.0245 Time taken: 48.00s \n",
      "Training acc over epoch: 0.1334 Training loss (for one batch) at step 4400: 0.0229 Time taken: 48.57s \n",
      "Training acc over epoch: 0.1294 Training loss (for one batch) at step 4450: 0.0215 Time taken: 49.14s \n",
      "Training acc over epoch: 0.1254 Training loss (for one batch) at step 4500: 0.0201 Time taken: 49.68s \n",
      "Training acc over epoch: 0.1214 Training loss (for one batch) at step 4550: 0.0188 Time taken: 50.23s \n",
      "Training acc over epoch: 0.1175 Training loss (for one batch) at step 4600: 0.0176 Time taken: 50.76s \n",
      "Training acc over epoch: 0.1135 Training loss (for one batch) at step 4650: 0.0164 Time taken: 51.28s \n",
      "Training acc over epoch: 0.1096 Training loss (for one batch) at step 4700: 0.0152 Time taken: 51.84s \n",
      "Training acc over epoch: 0.1058 Training loss (for one batch) at step 4750: 0.0142 Time taken: 52.39s \n",
      "Training acc over epoch: 0.1019 Training loss (for one batch) at step 4800: 0.0131 Time taken: 52.94s \n",
      "Training acc over epoch: 0.0981 Training loss (for one batch) at step 4850: 0.0122 Time taken: 53.48s \n",
      "Training acc over epoch: 0.0944 Training loss (for one batch) at step 4900: 0.0113 Time taken: 54.02s \n",
      "Training acc over epoch: 0.0907 Training loss (for one batch) at step 4950: 0.0104 Time taken: 54.55s \n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.Input(shape=(2,))\n",
    "hidden_layer = keras.layers.Dense(2)(input_layer)\n",
    "output_layer = keras.layers.Dense(1)(hidden_layer)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_function = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "my_train = custom_train(model, optimizer, loss_function, metric)\n",
    "loss_list, epoch_list = my_train.train(inputs, z, 5000, 15, 5, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e326cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1be8382f550>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(epoch_list, loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d354460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([[3, 2]], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e00347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14.065841]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e393f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
